from keras.layers import Dense
from keras import Model
from keras import models
from keras import optimizers
from keras import Sequential
from keras import layers
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.applications.vgg16 import VGG16
from keras import applications
from keras import utils
import os
import pickle
import numpy as np
import random 

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer

from keras.callbacks import ModelCheckpoint

import tensorflow as tf

import cv2

"""

    Author: Alexander Shellabear
    Email: alexshellabear@gmail.com

    Purpose:
        Take dataset and train the classifier (in this case vgg16 to determine if the selective search areas are correct)

    Lessons Learnt
        1) Must add a Flatten layer between the models
        2) Model.fit can support ImageGenerators however you will need to pass it as both the x and y dataset. hence (x_train,y_train) would become train_datagen
        3) Sometimes the data generated by generate_data_set_labels.py is way too much and will overload the memory of your machine + take forever to use. 
            Must incorporate logic to reduce number of images in the dataset or create an image generator to keep it in storage.
            at one point 31054 labels equated to 5gb of RAM, limit it to 20000 labels for memory consumption this will still take some time
        4) Had a for loop in get_resized_images_for_data_set, which would read the base image every time. Instead bring the base images into memory and then reference them as an index.
            The old slow code is below.
                data = []
                for label in data_set_labels:
                    base_image = cv2.imread(label["ImagePath"])
                    labeled_image = cv2.resize(base_image[label["Box"]['y1']:label["Box"]['y2'],label["Box"]['x1']:label["Box"]['x2']], config["ModelInput"], interpolation = cv2.INTER_AREA)
                    data.append(labeled_image)
        5) Had memory issues getting the whole dataset, especially with the batch size being 32. Instead I reduced it to 8 and it made training much better. 
        6) Could not save checkpoints because the metric used in compile was different in model checkpoint hence it did not work.
            https://stackoverflow.com/questions/61505749/tensorflowcan-save-best-model-only-with-val-acc-available-skipping
            To add to the accepted answer as I just struggled with this. Not only do you have to use the full the metric name, it must match for your model.compile, ModelCheckpoint, and EarlyStopping. I had one set to accuracy and the other two set to val_accuracy and it did not work.
"""

config = {
    "VGGModelPath" : "2. Models\\vggmodel.h5"
    ,"ModelInput" : (224,224)
    ,"MaxImagesToHoldInMemory" : 4000
    ,"EncodedLabels" : {
        "Background":0
        ,"Foreground" :1
        }
    ,"NumberOfCategories" : 2 
}

def count_number_of_this_labels(data_set_list:list,image_path_string:str):
    """
        Assumption: that data_set_list has dictionary elements with a 'ImagePath' element
    """
    return len([v for v in data_set_list if v["ImagePath"] == image_path_string])

def cv2_resize(base_image,label):
    """
        Wrapper for cv2.resize for readability
    """
    return cv2.resize(base_image[label["Box"]['y1']:label["Box"]['y2'],label["Box"]['x1']:label["Box"]['x2']], config["ModelInput"], interpolation = cv2.INTER_AREA)

def get_resized_images_for_data_set(base_image_paths_to_image:dict,data_set_labels: list):
    """
        Assumption 1: That data_set_list has dictionary elements with a 'ImagePath' and 'Box' elements
        Assumption 2: That the sub element 'Box' is a dictionary with 'x1','y1','x2','y2' elements
        Output:
            A numpy array of all images referenced by the data_set_labels
    """
    data = [cv2_resize(base_image_paths_to_image[label["ImagePath"]],label) for label in data_set_labels]
    return np.array(data)

def encode_labels(label_string):
    return [int(label == label_string) for label in config["EncodedLabels"]]

class MyLabelBinarizer(LabelBinarizer):
    def transform(self, y):
        Y = super().transform(y)
        if self.y_type_ == 'binary':
            return np.hstack((Y, 1-Y))
        else:
            return Y
    def inverse_transform(self, Y, threshold=None):
        if self.y_type_ == 'binary':
            return super().inverse_transform(Y[:, 0], threshold)
        else:
            return super().inverse_transform(Y, threshold)

def pre_process_data(x,y):
    x_preprocessed = applications.vgg16.preprocess_input(x) # Change to floats for each array
    y_preprocessed = utils.to_categorical(y,config["NumberOfCategories"]) # Change to one hot encoding, hence an array with the index of 1 corresponding to the label
    return x_preprocessed, y_preprocessed

def create_classifier_model():
    """
        Purpose: Uses the VGG16 architecture with imagenet weights, freezes the first 15 layers and then adds other dense layers for transfer learning
    """
    vggmodel = VGG16(weights='imagenet', include_top=False) # Load VGG16 for image classification, use include_top=False for retraining

    for layer in (vggmodel.layers)[:15]: # freeze the first 15 layers for retraining
        layer.trainable = False


    model = Sequential()
    model.add(layers.Lambda(lambda image: tf.image.resize(image, config["ModelInput"])))
    model.add(vggmodel) # Should have an output of 512 nodes
 
    model.add(layers.Flatten())

    model.add(layers.BatchNormalization(axis=-1))
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dropout(0.5))

    model.add(layers.BatchNormalization())
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.5))

    model.add(layers.BatchNormalization())
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.5))

    model.add(layers.BatchNormalization())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dropout(0.5))

    model.add(layers.BatchNormalization())
    model.add(layers.Dense(2, activation='softmax'))

    return model

def reduce_data_set(max_images_to_hold_in_memory,all_background_labels,all_foreground_labels):
    """
        Reduces the number of data to that allowed by the computer
        Assumption 1: The number of foreground labels is significantly less than the background labels
    """
    background_labels_to_retrieve = max_images_to_hold_in_memory - len(all_foreground_labels)
    random.shuffle(all_background_labels)
    shuffled_and_culled_background_labels =  all_background_labels[:background_labels_to_retrieve]
    return shuffled_and_culled_background_labels, all_foreground_labels

def show_bounding_box_label_and_resized_image(labels:list):
    """
        Goes through the x and y dataset and show
        1) Bounding box
        2) Resized Image
        3) Label_name & IOU
        4) Original Image path
    """
    exclude_images = [
        "1. Data Gen\\1. Data\\WIN_20210426_12_27_45_Pro.jpg"
        ,"1. Data Gen\\1. Data\\WIN_20210425_17_03_57_Pro.jpg"
        ,"1. Data Gen\\1. Data\\WIN_20210425_17_03_54_Pro.jpg"
        ,"1. Data Gen\\1. Data\\WIN_20210425_17_03_46_Pro.jpg"
        ,"1. Data Gen\\1. Data\\WIN_20210425_17_03_48_Pro.jpg"
        ,"1. Data Gen\\1. Data\\WIN_20210423_11_21_30_Pro.jpg"
    ] # TODO delete later

    for i, label in enumerate(labels):
        print(f"[{i}] label={label['Label']} iou={label['IOU']} box={label['Box']} image path={label['ImagePath']}")
        if not label['ImagePath'] in exclude_images:
            base_image = cv2.imread(label["ImagePath"])
            resized_cropped_image = cv2_resize(base_image,label)
            cv2.rectangle(base_image, (label["Box"]["x1"],label["Box"]["y1"]), (label["Box"]["x2"],label["Box"]["y2"]), (255,255,255), 4) 
            cv2.putText(base_image,f"{label['Label']} - IOU={label['IOU']}", 
                (100,100), 
                cv2.FONT_HERSHEY_SIMPLEX, 
                1,
                (255,255,255),
                2)
            
            cv2.imshow("BaseImage",base_image)
            cv2.imshow("ResizedImage",resized_cropped_image)
            cv2.waitKey(0)
    cv2.destroyAllWindows()



if __name__ == "__main__":
    model = create_classifier_model()
    
    all_background_labels = pickle.load(open("1. Data Gen\\1. Data\\background_labels.p","rb"))
    all_foreground_labels = pickle.load(open("1. Data Gen\\1. Data\\foreground_labels.p","rb"))

    background_labels, foreground_labels = reduce_data_set(config["MaxImagesToHoldInMemory"],all_background_labels,all_foreground_labels)

    # Test TODO delete later
    #show_bounding_box_label_and_resized_image(sorted(background_labels, reverse=True,key=lambda x: x["ImagePath"]))

    all_potential_base_image_paths = [v["ImagePath"] for v in (background_labels + foreground_labels)]
    all_unique_base_image_paths = list(set(all_potential_base_image_paths))
    all_unique_base_image_paths_to_image = {v:cv2.imread(v) for v in all_unique_base_image_paths}

    X_data = get_resized_images_for_data_set(all_unique_base_image_paths_to_image,foreground_labels + background_labels)
    Y_data = np.array([config["EncodedLabels"][v["Label"]] for v in (foreground_labels + background_labels)])

    X_data,Y_data = pre_process_data(X_data,Y_data)

    x_train, x_test , y_train, y_test = train_test_split(X_data,Y_data,test_size=0.10)

    trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)
    traindata = trdata.flow(x=x_train, y=y_train)
    tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)
    testdata = tsdata.flow(x=x_test, y=y_test)
    
    check_point = ModelCheckpoint(filepath="2. Models/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5",
                                              monitor="val_acc",
                                              mode="max",
                                              save_best_only=True,
                                              )

    model.compile(loss='categorical_crossentropy',
                optimizer=optimizers.RMSprop(lr=2e-5),
                metrics=['val_acc']
                )

    #history = model.fit_generator(generator= traindata, steps_per_epoch= 10, epochs= 1000, validation_data= testdata, validation_steps=2) # Removed callbacks
    #history = model.fit(x_train,y_train, batch_size=32, epochs=10, verbose=1,validation_data=(x_test, y_test) )
    history = model.fit(traindata, batch_size=8, epochs=20, verbose=1,validation_data=testdata,callbacks=[check_point] ) # Known to work callbacks=[check_point]
    model.save("vggtrained.h5")
    # TODO save history
    print("finished...")